{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e0869-4893-4799-a33a-fe630dc1c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf37e2-a086-415a-ad04-4a541f99d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Environment\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9088c2-405e-4f57-8b8d-eb9545715fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Clients\n",
    "\n",
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07761975-3baf-4d27-8344-fd8163ccdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Message\n",
    "\n",
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce3a199-1a71-4594-b84d-2a63eb1118e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to GPT\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages = messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e6beb-ce00-482b-98cc-047be7224d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_gpt(\"What is today's date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51771843-befd-48b2-9a6e-2c132ea0a9c1",
   "metadata": {},
   "source": [
    "# Creating User Interface Using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742014e-9c7a-48d0-ac6f-102b38394f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text):\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0682d8-ba0d-4748-b412-24d30d692daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d447a-8834-4172-9907-5ecba09e923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f596fd-4a3f-464b-bef5-1fa0e3b49de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn = shout,\n",
    "    inputs = [gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs = [gr.Textbox(label=\"Response:\", lines=8)],\n",
    "    flagging_mode = \"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9acda88-88eb-4af9-ad4d-56eef35cd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn = message_gpt,\n",
    "    inputs = [gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs = [gr.Textbox(label=\"Response:\", lines=8)],\n",
    "    flagging_mode = \"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee0fc14-1d67-46e9-89bd-89de6720c04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d75af6-4c31-4323-b79f-477d0d68650d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e08bc-ce93-426e-a133-5256b5749afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1be6bb2-6105-493a-8940-038c5e34b222",
   "metadata": {},
   "source": [
    "## Improving Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbed784-e7e1-449a-9b85-7aa4bc3cddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that responds in markdown\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn = message_gpt,\n",
    "    inputs = [gr.Textbox(label=\"Your message:\", lines=6)],\n",
    "    outputs = [gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode = \"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b25aaa-4c37-4b3c-af6a-5c6952de0150",
   "metadata": {},
   "source": [
    "## Integrating Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abd3f3-63e6-402d-b6e8-a9dc234b1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call to GPT using stream\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model = 'gpt-4o-mini',\n",
    "        messages = messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd4d38-21ac-408d-b286-e77d2fbd1dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that responds in markdown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13c77e-197b-4d43-9f9d-3050ea6f3fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn = stream_gpt,\n",
    "    inputs = [gr.Textbox(label=\"Your message:\")],\n",
    "    outputs = [gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode = \"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85cff81-7890-4ee2-a29e-dc169b208335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown Model\")\n",
    "    for chunk in result:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744650ef-a2b9-4779-ae4b-00d44dcc952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn = stream_model,\n",
    "    inputs = [gr.Textbox(label=\"Your message:\"), gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\")],\n",
    "    outputs = [gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode = \"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446c0e5-4873-4385-b8d2-85eac53d4a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
