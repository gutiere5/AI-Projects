{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1df941-c6c8-49dd-af6f-e43d80af2894",
   "metadata": {},
   "source": [
    "# Webpage Summarizer with Ollama and Llama 3.2\n",
    "\n",
    "This Jupyter Notebook demonstrates a simple yet powerful workflow for summarizing any webpage using a locally-run Large Language Model (LLM) with Ollama.\n",
    "\n",
    "**The process is as follows:**\n",
    "1.  Input a URL of a webpage.\n",
    "2.  The notebook fetches the HTML content of the page.\n",
    "3.  It uses the `BeautifulSoup` library to parse the HTML and extract the main text content, cleaning out irrelevant tags like scripts, styles, and images.\n",
    "4.  It constructs a prompt containing the extracted text.\n",
    "5.  It sends this prompt to a locally running Ollama model (`llama3.2`) to generate a concise summary.\n",
    "6.  The final summary is displayed in a clean, readable format.\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5edcca6-defa-4005-b19f-354dc7d60d8f",
   "metadata": {},
   "source": [
    "### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10542a46-be17-41bb-8f02-589717f64efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a94ecc-829d-4994-b9bf-67f5e81db247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9090310-2399-46b2-8428-7864c2b30f99",
   "metadata": {},
   "source": [
    "### Fetching and Cleaning Webpage Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30264d-f61a-4d67-a65c-583cae439f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d277db4-863b-498a-ac6c-e55737835855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can test beautiful soup and the website class is working.\n",
    "# Change the website and add print statements to follow along.\n",
    "\n",
    "website = Website(\"https://www.cnn.com/\")\n",
    "print(website.title)\n",
    "print(website.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11beee-fe3b-401f-9448-dd909b446572",
   "metadata": {},
   "source": [
    "### Summarizing the Content with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368885c-02d2-49b7-9b60-443a48c3de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749008f-2fde-4eca-94bf-b70f6b162cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175c0b6-f8ee-42b1-b381-b474e98f6e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab1855-cdfa-40d9-a4f3-ed32ddccd0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    \n",
    "    response = ollama.chat(\n",
    "        model=MODEL, \n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "\n",
    "    response\n",
    "    return response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cb8471-e36f-408f-a61f-c48bfcc0e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3447d097-b323-45ed-a1b8-9c5292c3e7c1",
   "metadata": {},
   "source": [
    "### Run the Summarizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438be778-114a-46f2-939e-6ddf28280096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change the URL in the cell below to summarize any webpage you want!\n",
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca541d85-553c-4d24-acf4-76724a58dc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
